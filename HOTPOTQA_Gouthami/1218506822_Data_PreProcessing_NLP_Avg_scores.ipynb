{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Data_PreProcessing_NLP_Backup.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8f0760b879a64fb58bb083ce8db3488d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1c535e339d0e40b2b0c3bc228cc1fd65",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3786c4fb8cfa4d1185db5689fdbe7fa8",
              "IPY_MODEL_5beb7f7e48304199af4c7d9ede6fd964"
            ]
          }
        },
        "1c535e339d0e40b2b0c3bc228cc1fd65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3786c4fb8cfa4d1185db5689fdbe7fa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8b9a8a44d4ff4267b03c8489fa96819b",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_360a91c6b59049f1a9e9a8d1b752cb43"
          }
        },
        "5beb7f7e48304199af4c7d9ede6fd964": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ad8d76ecd3b6426591acbc92d97ed794",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:12&lt;00:00,  2.57s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3ba0e043085e46078b36b134b7b2382a"
          }
        },
        "8b9a8a44d4ff4267b03c8489fa96819b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "360a91c6b59049f1a9e9a8d1b752cb43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ad8d76ecd3b6426591acbc92d97ed794": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3ba0e043085e46078b36b134b7b2382a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "41b4485532a54e81805a1b77b8d08876": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_04f4d435a6ea4e47b450761e9425cedc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b758ffb7a182432d886fdeec949ac5ec",
              "IPY_MODEL_0545956011354bd296cd686c181988b7"
            ]
          }
        },
        "04f4d435a6ea4e47b450761e9425cedc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b758ffb7a182432d886fdeec949ac5ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_73d8f8ad20764c1988eed7548af8e689",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 227,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 227,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_51029527b3f24d3c8bfd6a737de75484"
          }
        },
        "0545956011354bd296cd686c181988b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fa2cef757d8340aa8c7df2c63357f049",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 227/227 [01:55&lt;00:00,  1.97it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9d125e092d574c669839dd478fa0f28e"
          }
        },
        "73d8f8ad20764c1988eed7548af8e689": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "51029527b3f24d3c8bfd6a737de75484": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fa2cef757d8340aa8c7df2c63357f049": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9d125e092d574c669839dd478fa0f28e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFxtExkYOK4s"
      },
      "source": [
        "# Necessary Installations section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89yzY2GYTHgy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "db02c025-7ac4-4194-f788-592176487ce0"
      },
      "source": [
        "!pip3 install transformers\n",
        "!pip3 install unidecode\n",
        "!pip install pandas\n",
        "!pip install keras \n",
        "!pip install tensorflow\n",
        "!pip install torch\n",
        "!pip install git+https://github.com/AndriyMulyar/semantic-text-similarity\n",
        "!pip install urllib3==1.25.10\n",
        "!pip install awscli awsebcli botocore==1.18.18 --upgrade\n",
        "!pip install tqdm\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/4e/4f1ede0fd7a36278844a277f8d53c21f88f37f3754abf76a5d6224f76d4a/transformers-3.4.0-py3-none-any.whl (1.3MB)\n",
            "\r\u001b[K     |▎                               | 10kB 15.2MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 21.6MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 21.9MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 17.0MB/s eta 0:00:01\r\u001b[K     |█▎                              | 51kB 12.8MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61kB 11.7MB/s eta 0:00:01\r\u001b[K     |█▉                              | 71kB 12.1MB/s eta 0:00:01\r\u001b[K     |██                              | 81kB 11.5MB/s eta 0:00:01\r\u001b[K     |██▍                             | 92kB 11.3MB/s eta 0:00:01\r\u001b[K     |██▋                             | 102kB 11.4MB/s eta 0:00:01\r\u001b[K     |██▉                             | 112kB 11.4MB/s eta 0:00:01\r\u001b[K     |███▏                            | 122kB 11.4MB/s eta 0:00:01\r\u001b[K     |███▍                            | 133kB 11.4MB/s eta 0:00:01\r\u001b[K     |███▋                            | 143kB 11.4MB/s eta 0:00:01\r\u001b[K     |████                            | 153kB 11.4MB/s eta 0:00:01\r\u001b[K     |████▏                           | 163kB 11.4MB/s eta 0:00:01\r\u001b[K     |████▍                           | 174kB 11.4MB/s eta 0:00:01\r\u001b[K     |████▊                           | 184kB 11.4MB/s eta 0:00:01\r\u001b[K     |█████                           | 194kB 11.4MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 204kB 11.4MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 215kB 11.4MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 225kB 11.4MB/s eta 0:00:01\r\u001b[K     |██████                          | 235kB 11.4MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 245kB 11.4MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 256kB 11.4MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 266kB 11.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 276kB 11.4MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 286kB 11.4MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 296kB 11.4MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 307kB 11.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 317kB 11.4MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 327kB 11.4MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 337kB 11.4MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 348kB 11.4MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 358kB 11.4MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 368kB 11.4MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 378kB 11.4MB/s eta 0:00:01\r\u001b[K     |██████████                      | 389kB 11.4MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 399kB 11.4MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 409kB 11.4MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 419kB 11.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 430kB 11.4MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 440kB 11.4MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 450kB 11.4MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 460kB 11.4MB/s eta 0:00:01\r\u001b[K     |████████████                    | 471kB 11.4MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 481kB 11.4MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 491kB 11.4MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 501kB 11.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 512kB 11.4MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 522kB 11.4MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 532kB 11.4MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 542kB 11.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 552kB 11.4MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 563kB 11.4MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 573kB 11.4MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 583kB 11.4MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 593kB 11.4MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 604kB 11.4MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 614kB 11.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 624kB 11.4MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 634kB 11.4MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 645kB 11.4MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 655kB 11.4MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 665kB 11.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 675kB 11.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 686kB 11.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 696kB 11.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 706kB 11.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 716kB 11.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 727kB 11.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 737kB 11.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 747kB 11.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 757kB 11.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 768kB 11.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 778kB 11.4MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 788kB 11.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 798kB 11.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 808kB 11.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 819kB 11.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 829kB 11.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 839kB 11.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 849kB 11.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 860kB 11.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 870kB 11.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 880kB 11.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 890kB 11.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 901kB 11.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 911kB 11.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 921kB 11.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 931kB 11.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 942kB 11.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 952kB 11.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 962kB 11.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 972kB 11.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 983kB 11.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 993kB 11.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.0MB 11.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.0MB 11.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.0MB 11.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.0MB 11.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.0MB 11.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.1MB 11.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1MB 11.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.1MB 11.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.1MB 11.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.1MB 11.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.1MB 11.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.1MB 11.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.1MB 11.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.1MB 11.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1MB 11.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.2MB 11.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.2MB 11.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.2MB 11.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.2MB 11.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2MB 11.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2MB 11.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2MB 11.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2MB 11.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.2MB 11.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2MB 11.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3MB 11.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 18.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 48.1MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a5/78be1a55b2ac8d6a956f0a211d372726e2b1dd2666bb537fea9b03abd62c/tokenizers-0.9.2-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 47.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=859d001dc2bc266e22444d892f94d0c5eaaeb0c9b52562e4b762eb87d0b0734c\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.9.2 transformers-3.4.0\n",
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 15.3MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.1.1\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.4.3)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras) (1.15.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.33.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.35.1)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.10.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.5)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.17.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (50.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (3.3.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.6.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n",
            "Collecting git+https://github.com/AndriyMulyar/semantic-text-similarity\n",
            "  Cloning https://github.com/AndriyMulyar/semantic-text-similarity to /tmp/pip-req-build-qzk3fdqr\n",
            "  Running command git clone -q https://github.com/AndriyMulyar/semantic-text-similarity /tmp/pip-req-build-qzk3fdqr\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from semantic-text-similarity==1.0.3) (1.6.0+cu101)\n",
            "Collecting strsim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0d/95/14e5dea00c3bc73e5962261442957ee3691de8d51c97909ba7b2f46bf584/strsim-0.0.3-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.6MB/s \n",
            "\u001b[?25hCollecting fuzzywuzzy[speedup]\n",
            "  Downloading https://files.pythonhosted.org/packages/43/ff/74f23998ad2f93b945c0309f825be92e04e0348e062026998b5eefef4c33/fuzzywuzzy-0.18.0-py2.py3-none-any.whl\n",
            "Collecting pytorch-transformers==1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/89/ad0d6bb932d0a51793eaabcf1617a36ff530dc9ab9e38f765a35dc293306/pytorch_transformers-1.1.0-py3-none-any.whl (158kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 17.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from semantic-text-similarity==1.0.3) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->semantic-text-similarity==1.0.3) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->semantic-text-similarity==1.0.3) (1.18.5)\n",
            "Collecting python-levenshtein>=0.12; extra == \"speedup\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/a9/d1785c85ebf9b7dfacd08938dd028209c34a0ea3b1bcdb895208bd40a67d/python-Levenshtein-0.12.0.tar.gz (48kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.1.0->semantic-text-similarity==1.0.3) (2.23.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.1.0->semantic-text-similarity==1.0.3) (0.1.94)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.1.0->semantic-text-similarity==1.0.3) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers==1.1.0->semantic-text-similarity==1.0.3) (4.41.1)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/76/1f853a1ff319c173c638f38c34ebb389389253bf828e18fc4de52a2f4288/boto3-1.16.7-py2.py3-none-any.whl (129kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 28.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from python-levenshtein>=0.12; extra == \"speedup\"->fuzzywuzzy[speedup]->semantic-text-similarity==1.0.3) (50.3.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers==1.1.0->semantic-text-similarity==1.0.3) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers==1.1.0->semantic-text-similarity==1.0.3) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers==1.1.0->semantic-text-similarity==1.0.3) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers==1.1.0->semantic-text-similarity==1.0.3) (2020.6.20)\n",
            "Collecting botocore<1.20.0,>=1.19.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/58/64883046f9c98d9f94cc81174d0b83e0be35b8f6c252e255b709b9024ef1/botocore-1.19.7-py2.py3-none-any.whl (6.7MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 28.4MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.7->boto3->pytorch-transformers==1.1.0->semantic-text-similarity==1.0.3) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.20.0,>=1.19.7->boto3->pytorch-transformers==1.1.0->semantic-text-similarity==1.0.3) (1.15.0)\n",
            "Building wheels for collected packages: semantic-text-similarity, python-levenshtein\n",
            "  Building wheel for semantic-text-similarity (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for semantic-text-similarity: filename=semantic_text_similarity-1.0.3-cp36-none-any.whl size=416022 sha256=c83df4e66b90feb6c4daecda8d0b4d1a8f12557d2a9577a64b0b4df3fdda37dc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-2eiji8h3/wheels/14/52/19/87a3a9463ca3180550776ec1a20f90581e81c36a27142c7a15\n",
            "  Building wheel for python-levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-levenshtein: filename=python_Levenshtein-0.12.0-cp36-cp36m-linux_x86_64.whl size=144801 sha256=9dd90e8d0691f011e6658e38fc8396859b1297ba02b7502811810d561821fde3\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/c2/93/660fd5f7559049268ad2dc6d81c4e39e9e36518766eaf7e342\n",
            "Successfully built semantic-text-similarity python-levenshtein\n",
            "\u001b[31mERROR: botocore 1.19.7 has requirement urllib3<1.26,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: strsim, python-levenshtein, fuzzywuzzy, jmespath, botocore, s3transfer, boto3, pytorch-transformers, semantic-text-similarity\n",
            "Successfully installed boto3-1.16.7 botocore-1.19.7 fuzzywuzzy-0.18.0 jmespath-0.10.0 python-levenshtein-0.12.0 pytorch-transformers-1.1.0 s3transfer-0.3.3 semantic-text-similarity-1.0.3 strsim-0.0.3\n",
            "Collecting urllib3==1.25.10\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/f0/a391d1463ebb1b233795cabfc0ef38d3db4442339de68f847026199e69d7/urllib3-1.25.10-py2.py3-none-any.whl (127kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 11.7MB/s \n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: urllib3\n",
            "  Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed urllib3-1.25.10\n",
            "Collecting awscli\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/14/7f9080f5cd2dd65fe371791f42777e1bccef2bf9ca80ccfb3fe0fd051a6e/awscli-1.18.167-py2.py3-none-any.whl (3.4MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4MB 11.1MB/s \n",
            "\u001b[?25hCollecting awsebcli\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/0e/0df616d87aaa363454dbf342f7f3996bf036c1a4d5dbf64e8f046fd89142/awsebcli-3.19.2.tar.gz (249kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 48.5MB/s \n",
            "\u001b[?25hCollecting botocore==1.18.18\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2d/72/984ac8f33b5c8df5ff63f323a8724f65b4d0f8956968b942b77d35d3a1ef/botocore-1.18.18-py2.py3-none-any.whl (6.7MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 45.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from awscli) (0.3.3)\n",
            "Collecting rsa<=4.5.0,>=3.1.2; python_version != \"3.4\"\n",
            "  Downloading https://files.pythonhosted.org/packages/26/f8/8127fdda0294f044121d20aac7785feb810e159098447967a6103dedfb96/rsa-4.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: PyYAML<5.4,>=3.10; python_version != \"3.4\" in /usr/local/lib/python3.6/dist-packages (from awscli) (3.13)\n",
            "Collecting docutils<0.16,>=0.10\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/cd/a6aa959dca619918ccb55023b4cb151949c64d4d5d55b3f4ffd7eee0c6e8/docutils-0.15.2-py3-none-any.whl (547kB)\n",
            "\u001b[K     |████████████████████████████████| 552kB 51.1MB/s \n",
            "\u001b[?25hCollecting colorama<0.4.4,>=0.2.5; python_version != \"3.4\"\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Collecting cement==2.8.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/60/608f0b8975f4ee7deaaaa7052210d095e0b96e7cd3becdeede9bd13674a1/cement-2.8.2.tar.gz (165kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 56.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: future<0.17.0,>=0.16.0 in /usr/local/lib/python3.6/dist-packages (from awsebcli) (0.16.0)\n",
            "Collecting pathspec==0.5.9\n",
            "  Downloading https://files.pythonhosted.org/packages/84/2a/bfee636b1e2f7d6e30dd74f49201ccfa5c3cf322d44929ecc6c137c486c5/pathspec-0.5.9.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from awsebcli) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: requests<=2.24,>=2.20.1 in /usr/local/lib/python3.6/dist-packages (from awsebcli) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=20.0 in /usr/local/lib/python3.6/dist-packages (from awsebcli) (50.3.0)\n",
            "Collecting semantic_version==2.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bd/8d/49a968bafda84c2f1c39a9ed429e37cb75cc03896e8d6b873001e6456fad/semantic_version-2.5.0-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: six<=1.15.0,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from awsebcli) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor==1.1.0 in /usr/local/lib/python3.6/dist-packages (from awsebcli) (1.1.0)\n",
            "Collecting wcwidth<0.2.0,>=0.1.7\n",
            "  Downloading https://files.pythonhosted.org/packages/f6/d5/1ecdac957e3ea12c1b319fcdee8b6917ffaff8b4644d673c4d72d2f20b49/wcwidth-0.1.9-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.26,>=1.25.4 in /usr/local/lib/python3.6/dist-packages (from awsebcli) (1.25.10)\n",
            "Collecting docker-compose<1.26.0,>=1.25.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/35/1dfbb8e6b2ce5d290622a49cae0a7f3cf09cdc4341380a600aee00530881/docker_compose-1.25.5-py2.py3-none-any.whl (139kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 26.9MB/s \n",
            "\u001b[?25hCollecting blessed>=1.9.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/37/241fec1c8fa767b445c5afb5cfa7eb78cef07f85489b51c2cf292b530265/blessed-1.17.11-py2.py3-none-any.whl (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 12.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from botocore==1.18.18) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<=4.5.0,>=3.1.2; python_version != \"3.4\"->awscli) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<=2.24,>=2.20.1->awsebcli) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<=2.24,>=2.20.1->awsebcli) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<=2.24,>=2.20.1->awsebcli) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: docopt<1,>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from docker-compose<1.26.0,>=1.25.2->awsebcli) (0.6.2)\n",
            "Collecting websocket-client<1,>=0.32.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 56.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: jsonschema<4,>=2.5.1 in /usr/local/lib/python3.6/dist-packages (from docker-compose<1.26.0,>=1.25.2->awsebcli) (2.6.0)\n",
            "Collecting docker[ssh]<5,>=3.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/8c/8d42dbd83679483db207535f4fb02dc84325fa78b290f057694b057fcd21/docker-4.3.1-py2.py3-none-any.whl (145kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 51.6MB/s \n",
            "\u001b[?25hCollecting cached-property<2,>=1.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/48/19/f2090f7dad41e225c7f2326e4cfe6fff49e57dedb5b53636c9551f86b069/cached_property-1.5.2-py2.py3-none-any.whl\n",
            "Collecting dockerpty<1,>=0.4.1\n",
            "  Downloading https://files.pythonhosted.org/packages/8d/ee/e9ecce4c32204a6738e0a5d5883d3413794d7498fe8b06f44becc028d3ba/dockerpty-0.4.1.tar.gz\n",
            "Collecting texttable<2,>=0.9.0\n",
            "  Downloading https://files.pythonhosted.org/packages/06/f5/46201c428aebe0eecfa83df66bf3e6caa29659dbac5a56ddfd83cae0d4a4/texttable-1.6.3-py2.py3-none-any.whl\n",
            "Collecting paramiko>=2.4.2; extra == \"ssh\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/19/124e9287b43e6ff3ebb9cdea3e5e8e88475a873c05ccdf8b7e20d2c4201e/paramiko-2.7.2-py2.py3-none-any.whl (206kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 52.5MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/a2/6565c5271a79e3c96d7a079053b4d8408a740d4bf365f0f5f244a807bd09/cryptography-3.2.1-cp35-abi3-manylinux2010_x86_64.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 46.3MB/s \n",
            "\u001b[?25hCollecting pynacl>=1.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/57/2f5e6226a674b2bcb6db531e8b383079b678df5b10cdaa610d6cf20d77ba/PyNaCl-1.4.0-cp35-abi3-manylinux1_x86_64.whl (961kB)\n",
            "\u001b[K     |████████████████████████████████| 962kB 45.2MB/s \n",
            "\u001b[?25hCollecting bcrypt>=3.1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/70/6d218afbe4c73538053c1016dd631e8f25fffc10cd01f5c272d7acf3c03d/bcrypt-3.2.0-cp36-abi3-manylinux2010_x86_64.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 11.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.5->paramiko>=2.4.2; extra == \"ssh\"->docker[ssh]<5,>=3.7.0->docker-compose<1.26.0,>=1.25.2->awsebcli) (1.14.3)\n",
            "Requirement already satisfied, skipping upgrade: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.5->paramiko>=2.4.2; extra == \"ssh\"->docker[ssh]<5,>=3.7.0->docker-compose<1.26.0,>=1.25.2->awsebcli) (2.20)\n",
            "Building wheels for collected packages: awsebcli, cement, pathspec, dockerpty\n",
            "  Building wheel for awsebcli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for awsebcli: filename=awsebcli-3.19.2-cp36-none-any.whl size=357646 sha256=ecebf96a93052409d476b98252487fda829e5fa53e49ae3d442074e1ebb28ff0\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/29/e0/d6459b08d74d25f89da2f8dbe54a76bd578c4ef900b9f5d9aa\n",
            "  Building wheel for cement (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cement: filename=cement-2.8.2-cp36-none-any.whl size=99714 sha256=66639153970997b8a7e06d96e18d8a133a37984627159b37510117bd95d62bd7\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/9e/02/0af61a0ed625ea3decf29b8602fc0cbecc38943f19e076bb2e\n",
            "  Building wheel for pathspec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathspec: filename=pathspec-0.5.9-cp36-none-any.whl size=26357 sha256=d21a781ce0dcc1c070ec88d7287639a0fd7042784afbab7c26055803acf49bee\n",
            "  Stored in directory: /root/.cache/pip/wheels/45/cb/7e/ce6e6062c69446e39e328170524ca8213498bc66a74c6a210b\n",
            "  Building wheel for dockerpty (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dockerpty: filename=dockerpty-0.4.1-cp36-none-any.whl size=16606 sha256=62ddf26aef90cf65cc5ac08eff4f3688e3750b752a5ac3902140841e225fb27d\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/1e/86/bd0a97a0907c6c654af654d5875d1d4383dd1f575f77cee4aa\n",
            "Successfully built awsebcli cement pathspec dockerpty\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: boto3 1.16.7 has requirement botocore<1.20.0,>=1.19.7, but you'll have botocore 1.18.18 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: awscli 1.18.167 has requirement botocore==1.19.7, but you'll have botocore 1.18.18 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: awsebcli 3.19.2 has requirement botocore<1.20.0,>=1.19.0, but you'll have botocore 1.18.18 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: awsebcli 3.19.2 has requirement PyYAML<5.4,>=5.3.1, but you'll have pyyaml 3.13 which is incompatible.\u001b[0m\n",
            "Installing collected packages: botocore, rsa, docutils, colorama, awscli, cement, pathspec, semantic-version, wcwidth, websocket-client, cryptography, pynacl, bcrypt, paramiko, docker, cached-property, dockerpty, texttable, docker-compose, blessed, awsebcli\n",
            "  Found existing installation: botocore 1.19.7\n",
            "    Uninstalling botocore-1.19.7:\n",
            "      Successfully uninstalled botocore-1.19.7\n",
            "  Found existing installation: rsa 4.6\n",
            "    Uninstalling rsa-4.6:\n",
            "      Successfully uninstalled rsa-4.6\n",
            "  Found existing installation: docutils 0.16\n",
            "    Uninstalling docutils-0.16:\n",
            "      Successfully uninstalled docutils-0.16\n",
            "  Found existing installation: wcwidth 0.2.5\n",
            "    Uninstalling wcwidth-0.2.5:\n",
            "      Successfully uninstalled wcwidth-0.2.5\n",
            "Successfully installed awscli-1.18.167 awsebcli-3.19.2 bcrypt-3.2.0 blessed-1.17.11 botocore-1.18.18 cached-property-1.5.2 cement-2.8.2 colorama-0.4.3 cryptography-3.2.1 docker-4.3.1 docker-compose-1.25.5 dockerpty-0.4.1 docutils-0.15.2 paramiko-2.7.2 pathspec-0.5.9 pynacl-1.4.0 rsa-4.5 semantic-version-2.5.0 texttable-1.6.3 wcwidth-0.1.9 websocket-client-0.57.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "wcwidth"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgJirCHsZoO4"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from os import listdir\n",
        "from os.path import join\n",
        "import unidecode\n",
        "import re\n",
        "import logging\n",
        "from tqdm.notebook import tnrange\n",
        "import glob\n",
        "import json\n",
        "import os\n",
        "\n",
        "#For ploting results\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# DL Libraries\n",
        "from transformers import BertModel, AdamW, BertTokenizer, BertConfig, get_linear_schedule_with_warmup\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,TensorDataset)\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.stats import pearsonr\n",
        "from semantic_text_similarity.models import WebBertSimilarity\n",
        "from google.colab import drive\n",
        "\n",
        "# #NLTK Libraries\n",
        "# import nltk\n",
        "# nltk.download('punkt')\n",
        "# from nltk.tokenize import word_tokenize\n",
        "# from nltk.corpus import stopwords\n",
        "# nltk.download('stopwords')\n",
        "# stop_words = set(stopwords.words('english'))\n",
        "# nltk.download('wordnet')\n",
        "# nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Btlpy-D9dYDL"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "# print(\"device: {} n_gpu: {}\".format(device, n_gpu))\n",
        "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
        "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
        "                    level = logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "# print(logger)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTySPEHF_T5-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5deefc50-0f31-4e17-bf2f-efffe2f9175f"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYGMaJhmOK42"
      },
      "source": [
        "Sample Model Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCzkGq8uJC0d"
      },
      "source": [
        "from semantic_text_similarity.models import WebBertSimilarity\n",
        "\n",
        "web_model = WebBertSimilarity(device='cuda', batch_size=10) #defaults to GPU prediction\n",
        "\n",
        "#clinical_model = ClinicalBertSimilarity(device='cuda', batch_size=10) #defaults to GPU prediction\n",
        "\n",
        "web_model.predict([(\"She won an olympic gold medal\",\"The women is an olympic champion\")])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVRsIv1YGIqZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0kl-1vJRo6e"
      },
      "source": [
        "# Data Preprocessing section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kF-57dt5c_AO"
      },
      "source": [
        "Function Definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4BvDcc8T7uW"
      },
      "source": [
        "\n",
        "def generate_df(df, start,end):\n",
        "    new_df = pd.DataFrame(columns=['question-id','passage-id','query','passage','sentence', 'passage_len'])\n",
        "    pd.set_option('display.max_seq_items', None)\n",
        "    num_psges =  0\n",
        "    print(\"max length of the data : \",len(df))\n",
        "\n",
        "    for i in tnrange(start,end):\n",
        "        cntxt_len = len(df['context'][i])\n",
        "        num_psges  = num_psges + cntxt_len\n",
        "\n",
        "        query = str(df['question'][i] + df['answer'][i])\n",
        "        if len(query) < 2:\n",
        "            continue\n",
        "\n",
        "        for j  in range(0,cntxt_len):\n",
        "            passage  =  \"\".join(df['context'][i][j][1])\n",
        "            senList  = df['context'][i][j][1]\n",
        "            # passage_title =  df['context'][i][j][0]\n",
        "            for each_sen in senList:\n",
        "                # filtering empty sentences\n",
        "                if len(each_sen) < 2 :\n",
        "                    continue\n",
        "\n",
        "                ques_id = str(i+1)\n",
        "                psge_id  =  str(j+1)\n",
        "                new_row = {'question-id':ques_id,'passage-id':psge_id, 'query':query,'passage': passage,'sentence': each_sen,'passage_len': len(senList)}\n",
        "                \n",
        "                new_df =  new_df.append(new_row,ignore_index= True)\n",
        "    return  new_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CUqXgCZUGDQ"
      },
      "source": [
        "def generate_files(inpfilename,  start,  end):\n",
        "    df = pd.read_json(inpfilename)\n",
        "    new_df  =  generate_df(df,start,end)\n",
        "    final_df = pd.DataFrame(columns=['question-id', 'passage-id','passage','passage_len','sentence_1','sentence_2','score'])\n",
        "    final_df['question-id'] = new_df['question-id']\n",
        "    final_df['passage-id'] =  new_df['passage-id']\n",
        "    final_df['passage'] = new_df['passage']\n",
        "    final_df['passage_len'] = new_df['passage_len']\n",
        "    final_df['sentence_1'] = new_df['query']\n",
        "    final_df['sentence_2'] =  new_df['sentence']\n",
        "    return final_df\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqID-4q3dBWI"
      },
      "source": [
        "Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqmICuDnYpsA"
      },
      "source": [
        "\n",
        "start = 0\n",
        "end = 5\n",
        "# FOLDER = '/home/tharun/Downloads/Gouthami/NLP_Project/Training_Data/Submission'\n",
        "FOLDER = '/content/drive/My Drive/Courses/NLP/Project/data'\n",
        "JSON_FILE =  FOLDER +\"/hotpot_train_v1.1.json\"\n",
        "FILE_PREFIX  =  FOLDER +  '/parsed_df/parsed_data_'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wR5_aVgwPneH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "24bac18c-c755-478d-ff2a-a9edfe30a0ae"
      },
      "source": [
        "JSON_FILE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/Courses/NLP/Project/data/hotpot_train_v1.1.json'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pztCrQ50TfNB",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "8f0760b879a64fb58bb083ce8db3488d",
            "1c535e339d0e40b2b0c3bc228cc1fd65",
            "3786c4fb8cfa4d1185db5689fdbe7fa8",
            "5beb7f7e48304199af4c7d9ede6fd964",
            "8b9a8a44d4ff4267b03c8489fa96819b",
            "360a91c6b59049f1a9e9a8d1b752cb43",
            "ad8d76ecd3b6426591acbc92d97ed794",
            "3ba0e043085e46078b36b134b7b2382a"
          ]
        },
        "outputId": "484c73e1-0e06-46d1-9a2c-4560d74bbeaf"
      },
      "source": [
        "# generate_files(JSON_FILE, FILE_PREFIX, start,end, True)\n",
        "final_df =  generate_files(JSON_FILE,start, end)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length of the data :  90447\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f0760b879a64fb58bb083ce8db3488d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vN7OLE1K-vl-"
      },
      "source": [
        "final_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZ5DsBO5OK5N"
      },
      "source": [
        "# Scores Generation section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQq-TPZ9Bnkv",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222,
          "referenced_widgets": [
            "41b4485532a54e81805a1b77b8d08876",
            "04f4d435a6ea4e47b450761e9425cedc",
            "b758ffb7a182432d886fdeec949ac5ec",
            "0545956011354bd296cd686c181988b7",
            "73d8f8ad20764c1988eed7548af8e689",
            "51029527b3f24d3c8bfd6a737de75484",
            "fa2cef757d8340aa8c7df2c63357f049",
            "9d125e092d574c669839dd478fa0f28e"
          ]
        },
        "outputId": "f7dfc503-2e5d-4ca0-c52e-6d3c9e902554"
      },
      "source": [
        "web_model = WebBertSimilarity(device='cuda', batch_size=16) #defaults to GPU prediction\n",
        "\n",
        "for i in tnrange(len(final_df)):\n",
        "    sts_score  = web_model.predict([(final_df['sentence_1'][i],final_df['sentence_2'][i])])\n",
        "    final_df['score'][i]= np.round(sts_score,2)[0]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10/28/2020 21:58:15 - INFO - pytorch_transformers.tokenization_utils -   Model name '/root/.cache/torch/semantic_text_similarity/448b457fca135ab38bb3d6af49c5f220a8167e6b6ce9012f7df8172aa29865f9' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming '/root/.cache/torch/semantic_text_similarity/448b457fca135ab38bb3d6af49c5f220a8167e6b6ce9012f7df8172aa29865f9' is a path or url to a directory containing tokenizer files.\n",
            "10/28/2020 21:58:15 - INFO - pytorch_transformers.tokenization_utils -   Didn't find file /root/.cache/torch/semantic_text_similarity/448b457fca135ab38bb3d6af49c5f220a8167e6b6ce9012f7df8172aa29865f9/added_tokens.json. We won't load it.\n",
            "10/28/2020 21:58:15 - INFO - pytorch_transformers.tokenization_utils -   Didn't find file /root/.cache/torch/semantic_text_similarity/448b457fca135ab38bb3d6af49c5f220a8167e6b6ce9012f7df8172aa29865f9/special_tokens_map.json. We won't load it.\n",
            "10/28/2020 21:58:15 - INFO - pytorch_transformers.tokenization_utils -   loading file /root/.cache/torch/semantic_text_similarity/448b457fca135ab38bb3d6af49c5f220a8167e6b6ce9012f7df8172aa29865f9/vocab.txt\n",
            "10/28/2020 21:58:15 - INFO - pytorch_transformers.tokenization_utils -   loading file None\n",
            "10/28/2020 21:58:15 - INFO - pytorch_transformers.tokenization_utils -   loading file None\n",
            "10/28/2020 21:58:15 - INFO - pytorch_transformers.modeling_utils -   loading weights file /root/.cache/torch/semantic_text_similarity/448b457fca135ab38bb3d6af49c5f220a8167e6b6ce9012f7df8172aa29865f9/pytorch_model.bin\n",
            "10/28/2020 21:58:18 - INFO - root -   Initialized BertSentencePairSimilarity model from /root/.cache/torch/semantic_text_similarity/448b457fca135ab38bb3d6af49c5f220a8167e6b6ce9012f7df8172aa29865f9\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "41b4485532a54e81805a1b77b8d08876",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=227.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vn9sXuVsg3_J"
      },
      "source": [
        "final_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuggQgoxRs-J"
      },
      "source": [
        "      \n",
        "# SCORED_FOLDER = \"\".join((FOLDER, \"/scored_df/\"))\n",
        "\n",
        "# filename = SCORED_FOLDER +\"with_scores_\"+ str(start) +\"_\"+str(end) +\".csv\"\n",
        "\n",
        "# os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "# final_df.to_csv(filename,index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adiLFxLMcv81"
      },
      "source": [
        "Data Frame "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx29Srr_nIK4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa67615a-d3fe-4e71-fcf6-5cf7a365e4de"
      },
      "source": [
        "# print(filename)\n",
        "# result_df= pd.read_csv(filename)\n",
        "final_df['passage_len'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ueb81UTOK5c"
      },
      "source": [
        "# Data Processing Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zwg7nfDftoY9"
      },
      "source": [
        "output_df = pd.DataFrame(columns=['question', 'sentence','sia_score'])\n",
        "i =  0\n",
        "while i < len(final_df):\n",
        "  p_len = final_df['passage_len'][i]\n",
        "  score_sum = 0\n",
        "  k  = 0\n",
        "  while k < p_len:\n",
        "    print(score_sum)\n",
        "    score_sum = score_sum +  final_df['score'][i]\n",
        "    k = k+1\n",
        "    i  = i+1\n",
        "  avg_score =  (score_sum/ p_len)\n",
        "  new_row = {'question': final_df['sentence_1'][i-1], 'sentence' : final_df['passage'][i-1], 'sia_score' : avg_score }\n",
        "  output_df =  output_df.append(new_row,ignore_index= True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yOn2ZJIna9g"
      },
      "source": [
        "output_df = output_df.round({'sia_score': 2})\n",
        "OUT_FOLDER = \"\".join((FOLDER, \"/output_df/\"))\n",
        "filename = OUT_FOLDER +\"output_with_passage_\"+ str(start) +\"_\"+str(end) +\".csv\"\n",
        "os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "output_df.to_csv(filename,index = False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UInwoCV2OK5i"
      },
      "source": [
        "# The End #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTFB-HW7yDXc"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5ElDQxtZco9"
      },
      "source": [
        "# Experiments on MODELs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6fgG19HZViz"
      },
      "source": [
        "# #Class for Regression\n",
        "# class Regressor(nn.Module):\n",
        "\n",
        "#   def __init__(self,  model_path):\n",
        "#     super(Regressor, self).__init__()\n",
        "#     # self.bert = BertModel.from_pretrained(model_path)\n",
        "#     self.bert = BertModel.from_pretrained('/content/drive/My Drive/Courses/NLP/Project/model')\n",
        "#     self.out = nn.Linear(self.bert.config.hidden_size, 1)\n",
        "\n",
        "#   def forward(self, input_ids, attention_mask):\n",
        "#     output, pooler_out = self.bert(input_ids=input_ids, attention_mask=attention_mask)Preprocessing\n",
        "#     score= self.out(pooler_out)\n",
        "#     return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z724AT3Mu7du"
      },
      "source": [
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# n_gpu = torch.cuda.device_count()\n",
        "# print(\"device: {} n_gpu: {}\".format(device, n_gpu)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUKPkQelvE_1"
      },
      "source": [
        "# logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
        "#                     datefmt = '%m/%d/%Y %H:%M:%S',\n",
        "#                     level = logging.INFO)\n",
        "# logger = logging.getLogger(__name__)\n",
        "# print(logger)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdiixvzzLla-"
      },
      "source": [
        "# # memory footprint support libraries/code\n",
        "# !ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "# !pip install gputil\n",
        "# !pip install psutil\n",
        "# !pip install humanize\n",
        "\n",
        "# import psutil\n",
        "# import humanize\n",
        "# import os\n",
        "# import GPUtil as GPU\n",
        "\n",
        "# GPUs = GPU.getGPUs()\n",
        "# # XXX: only one GPU on Colab and isn’t guaranteed\n",
        "# gpu = GPUs[0]\n",
        "# def printm():\n",
        "#     process = psutil.Process(os.getpid())\n",
        "#     print(\"Gen RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available), \" |     Proc size: \" + humanize.naturalsize(process.memory_info().rss))\n",
        "#     print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total     {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "# printm()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9YAfRS5aTXB"
      },
      "source": [
        "# TRAINING AND EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLOvLUp5aWyv"
      },
      "source": [
        "# output_dir= '/content/drive/My Drive/Courses/NLP/Project/model'\n",
        "# output_result= '/content/drive/My Drive/Courses/NLP/Project/results'\n",
        "\n",
        "# if not os.path.exists(output_dir):\n",
        "#   os.makedirs(output_dir)\n",
        "\n",
        "# if not os.path.exists(output_result):\n",
        "#   os.makedirs(output_result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1ZM4N0abpyM"
      },
      "source": [
        "# for iteration in tnrange(epochs, desc='Epochs'):\n",
        "#   model.train()\n",
        "#   logger.info(\"Running for iteration: {}\".format(iteration+1))\n",
        "\n",
        "#   training_loss, training_steps=0,0\n",
        "#   true_labels, predicted_labels= list(), list()\n",
        "  \n",
        "#   for step, batch in enumerate(train_dataloader):\n",
        "#     batch = tuple(t.to(device) for t in batch)\n",
        "#     ip_ids, masks, gold_labels= batch\n",
        "#     score = model(ip_ids, attention_mask=masks)\n",
        "#     score = score.squeeze(1)\n",
        "#     loss= mse_loss(score, gold_labels.float())\n",
        "#     loss.backward()\n",
        "#     optimizer.step()\n",
        "#     optimizer.zero_grad()\n",
        "#     training_loss+=loss.item()\n",
        "#     training_steps+=1\n",
        "#     if (step+1)%1000 == 0:\n",
        "#       print(step+1)\n",
        "\n",
        "#     true_labels.extend(gold_labels.cpu().numpy())\n",
        "#     predicted_labels.extend(score.detach().cpu().numpy())\n",
        "  \n",
        "#   training_loss_for_epoch= training_loss/training_steps\n",
        "#   pcc= pearsonr(true_labels, predicted_labels)\n",
        "#   result = {'loss': training_loss_for_epoch, 'PCC': pcc[0]}\n",
        "#   print(result)\n",
        "\n",
        "#   model_to_save = model.bert.module if hasattr(model.bert, 'module') else model.bert\n",
        "#   model_to_save.save_pretrained(output_dir)\n",
        "\n",
        "#   torch.save(model.out.state_dict(), join(output_dir, 'model_state.bin'))\n",
        "\n",
        "#   print(\"Running validation for epoch: {}\".format(iteration+1))\n",
        "\n",
        "#   validation_loss, validation_steps=0,0\n",
        "#   true_labels, predicted_labels= list(), list()\n",
        "\n",
        "#   for step, batch in enumerate(dev_dataloader):\n",
        "#     batch = tuple(t.to(device) for t in batch)\n",
        "#     ip_ids, masks, gold_labels= batch\n",
        "#     score = model(ip_ids, attention_mask=masks)\n",
        "#     score = score.squeeze(1)\n",
        "#     loss= mse_loss(score, gold_labels)\n",
        "#     validation_loss+=loss.item()\n",
        "#     validation_steps+=1\n",
        "\n",
        "#     true_labels.extend(gold_labels.cpu().numpy())\n",
        "#     predicted_labels.extend(score.detach().cpu().numpy())\n",
        "  \n",
        "#   val_loss_for_epoch= validation_loss/validation_steps\n",
        "#   pcc= pearsonr(true_labels, predicted_labels)\n",
        "#   result = {'loss':val_loss_for_epoch, 'PCC': pcc[0]}\n",
        "#   print(result)\n",
        "  \n",
        "#   #Testing\n",
        "\n",
        "#   print(\"Running evaluation for epoch: {}\".format(iteration+1))\n",
        "\n",
        "#   true_labels, predicted_labels= list(), list()Preprocessing\n",
        "#   model.eval()\n",
        "#   with torch.no_grad():\n",
        "#     for step, batch in enumerate(test_dataloader):\n",
        "#       batch = tuple(t.to(device) for t in batch)\n",
        "#       ip_ids, masks, gold_labels= batch\n",
        "#       score = model(ip_ids, attention_mask=masks)\n",
        "#       score = score.squeeze(1)\n",
        "\n",
        "#       true_labels.extend(gold_labels.cpu().numpy())\n",
        "#       predicted_labels.extend(score.detach().cpu().numpy())\n",
        "  \n",
        "#   pcc= pearsonr(true_labels, predicted_labels)\n",
        "#   test_report= {'PCC': pcc[0]}\n",
        "#   print(test_report)\n",
        "\n",
        "#   with open(join(output_result, 'result_'+str(iteration+1)+'.json'), 'w') as fp:\n",
        "#     json.dump(test_report, fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4lNTpj1dwSl"
      },
      "source": [
        "Extras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvGwjitSdog3"
      },
      "source": [
        "# def sts_score_generator(df):\n",
        "#   tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "#   #tokenizer = BertTokenizer.from_pretrained('/content/drive/My Drive/Courses/NLP/Project/model')\n",
        "#   sts_dataloader = create_dataloader(tokenizer,df)\n",
        "#   sts_score  = []\n",
        "#   for step, batch in enumerate(sts_dataloader):\n",
        "#     batch = tuple(t.to(device) for t in batch)\n",
        "#     ip_ids,masks = batch\n",
        "#     score = model(ip_ids, attention_mask = masks)\n",
        "#     score  = score.squeeze(1)\n",
        "#     sts_score.extend(score.detach().cpu().numpy())\n",
        "#   return sts_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZ3Pe8J5x5lR"
      },
      "source": [
        "# def sts_score_generator(df):\n",
        "#   # tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "#   sts_dataloader = create_dataloader(tokenizer,df)\n",
        "#   sts_score  = []\n",
        "#   for step, batch in enumerate(sts_dataloader):\n",
        "#     batch = tuple(t.to(device) for t in batch)\n",
        "#     ip_ids,masks = batch\n",
        "#     score = model(ip_ids, attention_mask = masks)\n",
        "#     score  = score.squeeze(1)\n",
        "#     sts_score.extend(score.detach().cpu().numpy())\n",
        "#   return sts_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyUlXVlHPwk5"
      },
      "source": [
        "# load_data= '/content/drive/My Drive/Courses/NLP/Project/data'\n",
        "# train_df= pd.read_csv(join(load_data,'train.csv'))\n",
        "# train_df.columns =['caption', 'MSR', 'test','id', 'label','sentence_1','sentence_2','url','url_2']\n",
        "# dev_df= pd.read_csv(join(load_data,'dev.csv'))\n",
        "# dev_df.columns =['caption', 'MSR', 'test','id', 'label','sentence_1','sentence_2','url','url_2']\n",
        "# test_df= pd.read_csv(join(load_data,'test.csv'))\n",
        "# #test_df = new_df\n",
        "# test_df.columns =['caption', 'MSR', 'test','id', 'label','sentence_1','sentence_2','url','url_2']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRcCbBjwZyYr"
      },
      "source": [
        "# #Model Intialization\n",
        "\n",
        "# #epochs=10\n",
        "\n",
        "# #Load Model\n",
        "# model_path  = '/content/drive/My Drive/Courses/NLP/Project/model'\n",
        "# model= Regressor(model_path)\n",
        "# weights_score = torch.load(join(model_path,'model_state.bin'))\n",
        "# model.out.load_state_dict(weights_score)\n",
        "# model.to(device)\n",
        "\n",
        "# #To tokenize  the data\n",
        "# #tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# # # Prepare optimizer\n",
        "# # optimizer = AdamW(model.parameters(),lr=2e-5)\n",
        "\n",
        "# # #Loss Function\n",
        "# # mse_loss= nn.MSELoss().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61GBl4kBRXWr"
      },
      "source": [
        "# tokenizer = BertTokenizer.from_pretrained('/content/drive/My Drive/Courses/NLP/Project/model')\n",
        "# #tokenizer = BertTokenizer.from_pretrained('/content/drive/My Drive/Courses/NLP/Project/model')\n",
        "# # test_dataloader = create_dataloader(tokenizer, train_df)\n",
        "# # train_dataloader = create_dataloader(tokenizer, train_df)\n",
        "# # dev_dataloader = create_dataloader(tokenizer, dev_df)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}