{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1218519276 Synthetic Data Generation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vy791DSLZlCc",
        "outputId": "11b042a6-c21c-4b99-956e-92d3e7ad3828",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwZvK3nhZwEV"
      },
      "source": [
        "!pip3 install transformers\n",
        "!pip3 install unidecode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B74jlFkJZv8r"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import join\n",
        "import unidecode\n",
        "import re\n",
        "import logging\n",
        "from tqdm.notebook import tnrange\n",
        "import glob\n",
        "import json\n",
        "\n",
        "#For ploting results\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# DL Libraries\n",
        "from transformers import BertModel,RobertaModel,RobertaTokenizer, AdamW, BertTokenizer, BertConfig, get_linear_schedule_with_warmup\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,TensorDataset)\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "#NLTK Libraries\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhgKdq_DZv0P"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "print(\"device: {} n_gpu: {}\".format(device, n_gpu))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMjyn2cuZvm7"
      },
      "source": [
        "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
        "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
        "                    level = logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "print(logger)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBjIVyrTRlNZ"
      },
      "source": [
        "# Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBOJokWQRpFW"
      },
      "source": [
        "#taking the jsonl file and extracting it to generate the entire data in dataframe\n",
        "!pip install jsonlines\n",
        "import jsonlines\n",
        "id=[]  \n",
        "question=[]   \n",
        "label_list=[] \n",
        "A_choice=[] \n",
        "B_choice=[] \n",
        "C_choice=[] \n",
        "D_choice=[] \n",
        "Actual_Answer=[] \n",
        "fact_1=[] \n",
        "\n",
        "with jsonlines.open('/content/drive/My Drive/NLP/train_complete.jsonl') as f:\n",
        "    for line in f.iter():\n",
        "      question.append(line['question']['stem'])\n",
        "      label_list.append(line['question']['choices'])\n",
        "      id.append(line[\"id\"])\n",
        "      Actual_Answer.append(line['answerKey'])\n",
        "      fact_1.append(line['fact1'])\n",
        "\n",
        "for i in range(0,len(label_list)):\n",
        "  for j in range(0,4):\n",
        "    if(label_list[i][j]['label']==\"A\"):\n",
        "      A_choice.append(label_list[i][j]['text'])\n",
        "      \n",
        "    if(label_list[i][j]['label']==\"B\"):\n",
        "      B_choice.append(label_list[i][j]['text'])\n",
        "      \n",
        "    if(label_list[i][j]['label']==\"C\"):\n",
        "      C_choice.append(label_list[i][j]['text'])\n",
        "      \n",
        "    if(label_list[i][j]['label']==\"D\"):\n",
        "      D_choice.append(label_list[i][j]['text'])    \n",
        "  \n",
        "merged_list = tuple(zip(id,question,Actual_Answer,A_choice,B_choice,C_choice,D_choice,fact_1))\n",
        "data=pd.DataFrame(merged_list,columns=['ID','Question','Actual Answer','A','B','C','D','Fact 1'])\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZxdjzXHRpco"
      },
      "source": [
        "answer_candidates=[]\n",
        "flag = False\n",
        "for i in range(0,len(A_choice)):\n",
        "  R=[] \n",
        "  for j in range(0,4):\n",
        "    R.append(label_list[i][j]['text'])\n",
        "  answer_candidates.append(R)\n",
        "  \n",
        "#Getting the exactanswer candidates for each question in the exactanswer_candidates list\n",
        "exactanswer_candidates=[]\n",
        "flag = False\n",
        "for i in range(0,len(A_choice)):\n",
        "  R=[] \n",
        "  for j in range(0,4):\n",
        "    l = label_list[i][j]['label']\n",
        "    if(l == Actual_Answer[i]):\n",
        "      R.append(question[i])\n",
        "      R.append(label_list[i][j]['text'])\n",
        "      break\n",
        "  exactanswer_candidates.append(R)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6S03BRXURpTJ"
      },
      "source": [
        "exactanswer_candidates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUNbMg4ZRoxe",
        "outputId": "7d7e5f49-a086-4e0a-c1fa-1900c2f2d0c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Generating with the BM25 top choices for each choice\n",
        "!pip install rank_bm25\n",
        "from rank_bm25 import BM25Okapi\n",
        "corpus = []\n",
        "with open('/content/drive/My Drive/NLP/names.txt', 'r') as f:\n",
        "    corpus = f.readlines()\n",
        "tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
        "bm25 = BM25Okapi(tokenized_corpus)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rank_bm25 in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from rank_bm25) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtjUgA0sV0-t"
      },
      "source": [
        "question_list = []\n",
        "finallist = []\n",
        "for i in range(0,len(answer_candidates)):\n",
        "  question_list=[]\n",
        "  for j in range(0,4):\n",
        "    query = answer_candidates[i][j]\n",
        "    tokenized_query = query.split(\" \")\n",
        "    doc_scores = bm25.get_scores(tokenized_query)\n",
        "    l = bm25.get_top_n(tokenized_query, corpus, n=2)\n",
        "    question_list.append(l)\n",
        "  finallist.append(question_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaNovtmUWKCC"
      },
      "source": [
        "another_list = []\n",
        "for i in range(0,len(finallist)):\n",
        "  choice_list= []\n",
        "  for j in range(0,4):\n",
        "    for k in range(0,2):\n",
        "      alist=[]\n",
        "      alist.append(question[i] + ' ' + exactanswer_candidates[i][1])\n",
        "      alist.append(finallist[i][j][k])\n",
        "      choice_list.append(alist)\n",
        "  f_list=[]\n",
        "  f_list.append(question[i] + ' ' + exactanswer_candidates[i][1])\n",
        "  f_list.append(fact_1[i])\n",
        "  choice_list.append(f_list)\n",
        "  another_list.append(choice_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvVJUJ5AWKWa"
      },
      "source": [
        "q=[]\n",
        "a=[]\n",
        "for i in range(0, len(another_list)):\n",
        "  for j in range(0,9):\n",
        "    q.append(another_list[i][j][0])\n",
        "    a.append(another_list[i][j][1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FASZAQoaWJ0Z"
      },
      "source": [
        "merged_list = tuple(zip(q,a))\n",
        "final_data = pd.DataFrame(merged_list,columns=['Sentence_1','Sentence_2'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IcDl6oSZyfw",
        "outputId": "01f05f61-c1f6-4e31-f44f-7811f8858810",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "final_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence_1</th>\n",
              "      <th>Sentence_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The sun is responsible for plants sprouting, b...</td>\n",
              "      <td>hush puppies are food\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The sun is responsible for plants sprouting, b...</td>\n",
              "      <td>performing tricks is a learned behavior\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The sun is responsible for plants sprouting, b...</td>\n",
              "      <td>children inherit characteristics of parents\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The sun is responsible for plants sprouting, b...</td>\n",
              "      <td>reaping something is getting it\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The sun is responsible for plants sprouting, b...</td>\n",
              "      <td>a vase is an object\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44608</th>\n",
              "      <td>Harriet wants to know the area of a rectangula...</td>\n",
              "      <td>a mouse is a prey to a cat\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44609</th>\n",
              "      <td>Harriet wants to know the area of a rectangula...</td>\n",
              "      <td>a slash is a wound\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44610</th>\n",
              "      <td>Harriet wants to know the area of a rectangula...</td>\n",
              "      <td>a mouse is a prey to a cat\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44611</th>\n",
              "      <td>Harriet wants to know the area of a rectangula...</td>\n",
              "      <td>a slash is a wound\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44612</th>\n",
              "      <td>Harriet wants to know the area of a rectangula...</td>\n",
              "      <td>a ruler is used for measuring the length of an...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>44613 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Sentence_1                                         Sentence_2\n",
              "0      The sun is responsible for plants sprouting, b...                            hush puppies are food\\n\n",
              "1      The sun is responsible for plants sprouting, b...          performing tricks is a learned behavior\\n\n",
              "2      The sun is responsible for plants sprouting, b...      children inherit characteristics of parents\\n\n",
              "3      The sun is responsible for plants sprouting, b...                  reaping something is getting it\\n\n",
              "4      The sun is responsible for plants sprouting, b...                              a vase is an object\\n\n",
              "...                                                  ...                                                ...\n",
              "44608  Harriet wants to know the area of a rectangula...                       a mouse is a prey to a cat\\n\n",
              "44609  Harriet wants to know the area of a rectangula...                               a slash is a wound\\n\n",
              "44610  Harriet wants to know the area of a rectangula...                       a mouse is a prey to a cat\\n\n",
              "44611  Harriet wants to know the area of a rectangula...                               a slash is a wound\\n\n",
              "44612  Harriet wants to know the area of a rectangula...  a ruler is used for measuring the length of an...\n",
              "\n",
              "[44613 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgkwXhFbXtAh"
      },
      "source": [
        "# Web STS BERT Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwYP9RE7XoKJ"
      },
      "source": [
        "!pip install git+https://github.com/AndriyMulyar/semantic-text-similarity\n",
        "!pip install urllib3==1.25.10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxNZLE32aEBG"
      },
      "source": [
        "from semantic_text_similarity.models import WebBertSimilarity\n",
        "web_model = WebBertSimilarity(device='cuda', batch_size=32) #defaults to GPU prediction\n",
        "\n",
        "web_model.predict([(\"She won an olympic gold medal\",\"The women is an olympic champion\")])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vm1Tg2Z-Yaj1"
      },
      "source": [
        "sts_score = []\n",
        "def predict_score(df):\n",
        "  web_model = WebBertSimilarity(device='cuda', batch_size=32) #defaults to GPU prediction\n",
        "  for i in  range(len(df)):\n",
        "    sts_score.extend(web_model.predict([(df['sentence_1'][i],df['sentence_2'][i])]))\n",
        "    print(i,  df['sentence_1'][i], df['sentence_2'][i], sts_score[i])\n",
        "  return  sts_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EfZSW42-PXb"
      },
      "source": [
        "final_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueJkcg1fYaYv"
      },
      "source": [
        "final_df = pd.DataFrame()\n",
        "new_df2 = final_data\n",
        "final_df['sentence_1'] = final_data['Sentence_1']\n",
        "final_df['sentence_2'] =  final_data['Sentence_2']\n",
        "#sts_score  = []\n",
        "sts_score = predict_score(final_df)\n",
        "final_df['score'] = sts_score\n",
        "final_df = final_df.round({'score': 2})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eL1NsXTueHDQ"
      },
      "source": [
        "final_df[50:70]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHzmTZPve2Ls"
      },
      "source": [
        "choice_list = []\n",
        "for i in range(0,len(finallist)):\n",
        "  for j in range(0,9):\n",
        "    choice_list.append(question[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ODGDbK2fL9z"
      },
      "source": [
        "choice_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wxgZb50fNSw"
      },
      "source": [
        "merged = tuple(zip(choice_list,final_df['sentence_2'], final_df['score']))\n",
        "pr = pd.DataFrame(merged,columns=['Question','Sentence','Sia_Score'])\n",
        "pr['Sia_Score'] = pr['Sia_Score'] * 0.8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iH2vBgljskQG"
      },
      "source": [
        "pr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCPslLOcf0cg"
      },
      "source": [
        "pr.to_csv('/content/drive/My Drive/NLP/NLPDataset.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZM_M7KGjJCq"
      },
      "source": [
        "# Roberta Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPMrCg9MjNn_"
      },
      "source": [
        "def create_dataloader(tokenizer, df):\n",
        "    input_ids= list()\n",
        "    attention_masks= list()\n",
        "    print(\"Shape: {}\".format(df.shape))\n",
        "    special_sentences_1 = [sentence for i, sentence in enumerate(df.sentence_1)]\n",
        "    special_sentences_2 = [\" [SEP] \" + str(sentence) for i, sentence in enumerate(df.sentence_2)]\n",
        "    special_sentences = [str(i) + str(j) for i, j in zip(special_sentences_1, special_sentences_2)]\n",
        "\n",
        "    for sentence in special_sentences:\n",
        "      encoded_text = tokenizer.encode_plus(sentence, max_length=128, add_special_tokens=True, return_token_type_ids=False, \n",
        "                                       padding='max_length', return_attention_mask=True, truncation=True)\n",
        "      input_ids.append(encoded_text['input_ids'])\n",
        "      attention_masks.append(encoded_text['attention_mask'])\n",
        "\n",
        "    inputs = torch.tensor(input_ids).to(device)\n",
        "    masks = torch.tensor(attention_masks).to(device)\n",
        "    data = TensorDataset(inputs, masks)\n",
        "    sampler = RandomSampler(data)\n",
        "    dataloader = DataLoader(data, sampler=sampler, batch_size=4)\n",
        "    return dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lmqHaOAjOEh"
      },
      "source": [
        "class Regressor(nn.Module):\n",
        "  def __init__(self,  model_path):\n",
        "    super(Regressor, self).__init__()\n",
        "    # self.bert = BertModel.from_pretrained(model_path)\n",
        "    self.bert = RobertaModel.from_pretrained('/content/drive/My Drive/NLP/roberta-model')\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, 1)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    output, pooler_out = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "    score= self.out(pooler_out)\n",
        "    return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekoISQwzkdSE"
      },
      "source": [
        "model_path  = '/content/drive/My Drive/NLP/roberta-model'\n",
        "model= Regressor(model_path)\n",
        "weights_score = torch.load(join(model_path,'model_state.bin'))\n",
        "model.out.load_state_dict(weights_score)\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReWzASnUj5Pp"
      },
      "source": [
        "def sts_score_generator(df):\n",
        "  tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "  sts_dataloader = create_dataloader(tokenizer,df)\n",
        "  sts_score  = []\n",
        "  for step, batch in enumerate(sts_dataloader):\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    ip_ids,masks = batch\n",
        "    score = model(ip_ids, attention_mask = masks)\n",
        "    score  = score.squeeze(1)\n",
        "    sts_score.extend(score.detach().cpu().numpy())\n",
        "  return sts_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juT4FZWzjWbC",
        "outputId": "3705a7c0-c2ad-421c-b3b3-702f4be034da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "source": [
        "final_df_r = pd.DataFrame()\n",
        "final_df_r['sentence_1'] =  final_data['Sentence_1']\n",
        "final_df_r['sentence_2'] = final_data['Sentence_2']\n",
        "\n",
        "sts_score = sts_score_generator(final_df_r)\n",
        "final_df_r['score'] = sts_score\n",
        "final_df_r.round({'score': 2})\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape: (44613, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_1</th>\n",
              "      <th>sentence_2</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The sun is responsible for plants sprouting, b...</td>\n",
              "      <td>hush puppies are food\\n</td>\n",
              "      <td>0.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The sun is responsible for plants sprouting, b...</td>\n",
              "      <td>performing tricks is a learned behavior\\n</td>\n",
              "      <td>1.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The sun is responsible for plants sprouting, b...</td>\n",
              "      <td>children inherit characteristics of parents\\n</td>\n",
              "      <td>2.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The sun is responsible for plants sprouting, b...</td>\n",
              "      <td>reaping something is getting it\\n</td>\n",
              "      <td>1.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The sun is responsible for plants sprouting, b...</td>\n",
              "      <td>a vase is an object\\n</td>\n",
              "      <td>2.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44608</th>\n",
              "      <td>Harriet wants to know the area of a rectangula...</td>\n",
              "      <td>a mouse is a prey to a cat\\n</td>\n",
              "      <td>0.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44609</th>\n",
              "      <td>Harriet wants to know the area of a rectangula...</td>\n",
              "      <td>a slash is a wound\\n</td>\n",
              "      <td>3.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44610</th>\n",
              "      <td>Harriet wants to know the area of a rectangula...</td>\n",
              "      <td>a mouse is a prey to a cat\\n</td>\n",
              "      <td>2.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44611</th>\n",
              "      <td>Harriet wants to know the area of a rectangula...</td>\n",
              "      <td>a slash is a wound\\n</td>\n",
              "      <td>0.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44612</th>\n",
              "      <td>Harriet wants to know the area of a rectangula...</td>\n",
              "      <td>a ruler is used for measuring the length of an...</td>\n",
              "      <td>0.78</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>44613 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              sentence_1  ... score\n",
              "0      The sun is responsible for plants sprouting, b...  ...  0.43\n",
              "1      The sun is responsible for plants sprouting, b...  ...  1.08\n",
              "2      The sun is responsible for plants sprouting, b...  ...  2.32\n",
              "3      The sun is responsible for plants sprouting, b...  ...  1.49\n",
              "4      The sun is responsible for plants sprouting, b...  ...  2.17\n",
              "...                                                  ...  ...   ...\n",
              "44608  Harriet wants to know the area of a rectangula...  ...  0.24\n",
              "44609  Harriet wants to know the area of a rectangula...  ...  3.52\n",
              "44610  Harriet wants to know the area of a rectangula...  ...  2.37\n",
              "44611  Harriet wants to know the area of a rectangula...  ...  0.63\n",
              "44612  Harriet wants to know the area of a rectangula...  ...  0.78\n",
              "\n",
              "[44613 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPy2Rz8HjWOe"
      },
      "source": [
        "final_df_r.to_csv('/content/drive/My Drive/NLP/roberta-model-res.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxK3vk8KnEkh"
      },
      "source": [
        "# Bert Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7qlhqCanHOJ"
      },
      "source": [
        "def create_dataloader(tokenizer, df):\n",
        "    input_ids= list()\n",
        "    attention_masks= list()\n",
        "    print(\"Shape: {}\".format(df.shape))\n",
        "    special_sentences_1 = [sentence for i, sentence in enumerate(df.sentence_1)]\n",
        "    special_sentences_2 = [\" [SEP] \" + str(sentence) for i, sentence in enumerate(df.sentence_2)]\n",
        "    special_sentences = [str(i) + str(j) for i, j in zip(special_sentences_1, special_sentences_2)]\n",
        "\n",
        "    for sentence in special_sentences:\n",
        "      encoded_text = tokenizer.encode_plus(sentence, max_length=128, add_special_tokens=True, return_token_type_ids=False, \n",
        "                                       padding='max_length', return_attention_mask=True, truncation=True)\n",
        "      input_ids.append(encoded_text['input_ids'])\n",
        "      attention_masks.append(encoded_text['attention_mask'])\n",
        "\n",
        "    inputs = torch.tensor(input_ids).to(device)\n",
        "    masks = torch.tensor(attention_masks).to(device)\n",
        "    data = TensorDataset(inputs, masks)\n",
        "    sampler = RandomSampler(data)\n",
        "    dataloader = DataLoader(data, sampler=sampler, batch_size=4)\n",
        "    return dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4h4XAnRnSEo"
      },
      "source": [
        "class Regressor(nn.Module):\n",
        "  def __init__(self,  model_path):\n",
        "    super(Regressor, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained('/content/drive/My Drive/NLP/model')\n",
        "    #self.bert = RobertaModel.from_pretrained('/content/drive/My Drive/NLP/roberta-model')\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, 1)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    output, pooler_out = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "    score= self.out(pooler_out)\n",
        "    return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sERjSx8n5Iq",
        "outputId": "4cb535c7-9f4a-4f55-9c42-fd4d2634444b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_path  = '/content/drive/My Drive/NLP/model'\n",
        "model= Regressor(model_path)\n",
        "weights_score = torch.load(join(model_path,'model_state.bin'))\n",
        "model.out.load_state_dict(weights_score)\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Regressor(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (out): Linear(in_features=768, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zNcoOkLnfbg"
      },
      "source": [
        "def sts_score_generator(df):\n",
        "  tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "  sts_dataloader = create_dataloader(tokenizer,df)\n",
        "  sts_score  = []\n",
        "  for step, batch in enumerate(sts_dataloader):\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    ip_ids,masks = batch\n",
        "    score = model(ip_ids, attention_mask = masks)\n",
        "    score  = score.squeeze(1)\n",
        "    sts_score.extend(score.detach().cpu().numpy())\n",
        "  return sts_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3AxzXponf9O"
      },
      "source": [
        "final_df_b = pd.DataFrame()\n",
        "final_df_b['sentence_1'] =  final_data['Sentence_1']\n",
        "final_df_b['sentence_2'] = final_data['Sentence_2']\n",
        "sts_score = []\n",
        "sts_score = sts_score_generator(final_df_b)\n",
        "final_df_b['score'] = sts_score\n",
        "final_df_b.round({'score': 2})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exSUcYIS4blq"
      },
      "source": [
        "# With Facts\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7VaFGiWrBhN"
      },
      "source": [
        "final_df_b.to_csv('/content/drive/My Drive/NLP/bert-model-res.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQe268gJrC1d"
      },
      "source": [
        "another_fact = []\n",
        "for i in range(0,len(finallist)):\n",
        "  choice_list= []\n",
        "  for j in range(0,4):\n",
        "    for k in range(0,2):\n",
        "      alist=[]\n",
        "      alist.append(question[i] + ' ' + fact_1[i])\n",
        "      alist.append(finallist[i][j][k])\n",
        "      choice_list.append(alist)\n",
        "  f_list=[]\n",
        "  f_list.append(question[i] + ' ' + fact_1[i])\n",
        "  f_list.append(A_choice[i])\n",
        "  choice_list.append(f_list)\n",
        "  f_list=[]\n",
        "  f_list.append(question[i] + ' ' + fact_1[i])\n",
        "  f_list.append(B_choice[i])\n",
        "  choice_list.append(f_list)\n",
        "  f_list=[]\n",
        "  f_list.append(question[i] + ' ' + fact_1[i])\n",
        "  f_list.append(C_choice[i])\n",
        "  choice_list.append(f_list)\n",
        "  f_list=[]\n",
        "  f_list.append(question[i] + ' ' + fact_1[i])\n",
        "  f_list.append(D_choice[i])\n",
        "  choice_list.append(f_list)\n",
        "  another_fact.append(choice_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymmpxvj041Kr"
      },
      "source": [
        "another_fact[0:20]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWN7dNH05PzG"
      },
      "source": [
        "q_f=[]\n",
        "a_f=[]\n",
        "for i in range(0, len(another_list)):\n",
        "  for j in range(0,12):\n",
        "    q_f.append(another_fact[i][j][0])\n",
        "    a_f.append(another_fact[i][j][1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G827wrTL5nj2"
      },
      "source": [
        "merged_fact = tuple(zip(q_f,a_f))\n",
        "final_fact = pd.DataFrame(merged_fact,columns=['Sentence_1','Sentence_2'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6L-loHq5s-r",
        "outputId": "2b891a33-405a-4d99-a0fd-ef319b7d9689",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "final_df_f = pd.DataFrame()\n",
        "new_df2_f = final_fact\n",
        "final_df_f['sentence_1'] = final_fact['Sentence_1']\n",
        "final_df_f['sentence_2'] =  final_fact['Sentence_2']\n",
        "sts_score  = []\n",
        "sts_score = predict_score(final_df_f)\n",
        "final_df_f['score'] = sts_score\n",
        "final_df_f = np.round({'score': 2})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-eb81aef32a7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfinal_df_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnew_df2_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_fact\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfinal_df_f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence_1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_fact\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sentence_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfinal_df_f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence_2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mfinal_fact\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sentence_2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msts_score\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'final_fact' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNPoYPLO6KfA"
      },
      "source": [
        "final_fact"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}